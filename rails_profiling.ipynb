{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Clean accuracy is 0.8759999871253967.\n",
      "Adversarial accuracy (CNN) is 0.32199999690055847.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.VGG import VGG\n",
    "from pgd import PGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if importing locals\n",
    "from rails import RAILS\n",
    "from aise import AISE\n",
    "import aise\n",
    "\n",
    "\n",
    "CIFAR_CONFIGS = {\n",
    "    \"start_layer\": 1,\n",
    "    \"n_class\": 10,\n",
    "    \"aise_params\": [\n",
    "        {\"hidden_layer\": 2, \"sampling_temperature\": 1, \"max_generation\": 10, \"mut_range\": (.005, .015)},\n",
    "        {\"hidden_layer\": 3, \"sampling_temperature\": 10, \"max_generation\": 5, \"mut_range\": (.005, .015)}\n",
    "    ]\n",
    "}\n",
    "\n",
    "ROOT = \"./datasets\"\n",
    "TRANSFORM = transforms.ToTensor()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = datasets.CIFAR10(root=ROOT, download=True, train=True, transform=TRANSFORM)\n",
    "test_data = datasets.CIFAR10(root=ROOT, download=True, train=False, transform=TRANSFORM)\n",
    "#     train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "#     test_loader = DataLoader(test_data, batch_size=1024, shuffle=False)\n",
    "\n",
    "x_train = (torch.FloatTensor(train_data.data[:50000])/255).permute(0,3,1,2)\n",
    "y_train = torch.LongTensor(train_data.targets[:50000])\n",
    "\n",
    "model = VGG()\n",
    "model.load_state_dict(torch.load(\n",
    "    \"./model_weights/cifar_vgg16.pt\", map_location=DEVICE\n",
    ")['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "pgd = PGD(eps=8/255,step=2/255,max_iter=10, batch_size=256)\n",
    "\n",
    "x_batch = (torch.FloatTensor(test_data.data[:1000])/255).permute(0,3,1,2)\n",
    "y_batch = torch.LongTensor(test_data.targets[:1000])\n",
    "\n",
    "x_adv = pgd.generate(model, x_batch, y_batch, device=DEVICE)\n",
    "\n",
    "pred_clean = model(x_batch.to(DEVICE))[-1].max(dim=1)[1].detach().cpu()\n",
    "clean_acc = (pred_clean == y_batch).float().mean().item()\n",
    "print(\"Clean accuracy is {}.\".format(clean_acc))\n",
    "\n",
    "pred_adv = model(x_adv.to(DEVICE))[-1].max(dim=1)[1].detach().cpu()\n",
    "adv_acc = (pred_adv == y_batch).float().mean().item()\n",
    "print(\"Adversarial accuracy (CNN) is {}.\".format(adv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# \"\"\"\n",
    "# rails constructor execution time\n",
    "# \"\"\"\n",
    "\n",
    "# rails = RAILS(model, CIFAR_CONFIGS, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nload the memory profiler \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\"\"\"\n",
    "load the line profiler\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\"\"\"\n",
    "load the memory profiler \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         3 function calls in 0.000 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rails constructor line by line profiling\n",
    "\"\"\"\n",
    "    \n",
    "%prun \n",
    "\n",
    "rails = RAILS(model, CIFAR_CONFIGS, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 296.586 s\n",
       "File: /home/cstansbu/RAILS/rails.py\n",
       "Function: predict at line 73\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    73                                               def predict(self, x):\n",
       "    74         1         68.0     68.0      0.0          with torch.no_grad():\n",
       "    75         3      71631.0  23877.0      0.0              x_start = torch.cat([\n",
       "    76                                                           self._model.to_start(x[i:i + self.batch_size].to(DEVICE)).cpu()\n",
       "    77         1          8.0      8.0      0.0                  for i in range(0, x.size(0), self.batch_size)\n",
       "    78         1          3.0      3.0      0.0              ], dim=0)\n",
       "    79         1         52.0     52.0      0.0          pred = np.zeros((x_start.size(0), self.n_class))\n",
       "    80         3          9.0      3.0      0.0          for aise in self.aises:\n",
       "    81         2  296514495.0 148257247.5    100.0              pred = pred + aise(x_start)\n",
       "    82         1          1.0      1.0      0.0          return pred"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rails predict\n",
    "\"\"\"\n",
    "    \n",
    "%lprun -f rails.predict rails.predict(x_adv.to(DEVICE)).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 318.572 s\n",
       "File: /home/cstansbu/RAILS/aise.py\n",
       "Function: clonal_expansion at line 360\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   360                                               def clonal_expansion(self, ant, y_ant=None):\n",
       "   361         1         23.0     23.0      0.0          logger.info(\"Clonal expansion starts...\")\n",
       "   362         1      10967.0  10967.0      0.0          ant_tran = self._hidden_repr_mapping(ant.detach())\n",
       "   363         1   69096436.0 69096436.0     21.7          nbc_ind = self._query_nns_ind(ant_tran.detach().cpu().numpy())\n",
       "   364         2  249464112.0 124732056.0     78.3          mem_bcs, mem_labs, pla_bcs, pla_labs, ant_logs = self.generate_b_cells(\n",
       "   365         1        149.0    149.0      0.0              ant.flatten(start_dim=1),\n",
       "   366         1          1.0      1.0      0.0              ant_tran,\n",
       "   367         1          0.0      0.0      0.0              nbc_ind,\n",
       "   368         1          0.0      0.0      0.0              y_ant\n",
       "   369                                                   )\n",
       "   370         1          6.0      6.0      0.0          if self.keep_memory:\n",
       "   371                                                       logger.info(\"{} plasma B cells and {} memory generated!\".format(pla_bcs.shape[0] * self.n_plasma,\n",
       "   372                                                                                                                       mem_bcs.shape[0] * self.n_memory))\n",
       "   373                                                   else:\n",
       "   374         1         52.0     52.0      0.0              logger.info(\"{} plasma B cells generated!\".format(pla_bcs.shape[0] * self.n_plasma))\n",
       "   375         1          1.0      1.0      0.0          return mem_bcs, mem_labs, pla_bcs, pla_labs, ant_logs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "aise profile\n",
    "\"\"\"\n",
    "\n",
    "x_start = torch.cat([\n",
    "    rails._model.to_start(x_adv[i:i + rails.batch_size].to(DEVICE)).cpu()\n",
    "    for i in range(0, x_adv.size(0), rails.batch_size)\n",
    "], dim=0)\n",
    "\n",
    "params = {\n",
    "    \"hidden_layer\": 2, \n",
    "    \"sampling_temperature\": 1, \n",
    "    \"max_generation\": 10, \n",
    "    \"mut_range\": (.005, .015)\n",
    "}\n",
    "    \n",
    "aise = AISE(model=rails._model, \n",
    "     x_orig=rails.x_train, \n",
    "     y_orig=rails.y_train, \n",
    "     dataset = \"cifar\", \n",
    "     **params)\n",
    "\n",
    "\n",
    "%lprun -f  aise.clonal_expansion aise.clonal_expansion(x_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 237.348 s\n",
       "File: /home/cstansbu/RAILS/aise.py\n",
       "Function: generate_b_cells at line 237\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   237                                               def generate_b_cells(self, ant, ant_tran, nbc_ind, y_ant=None):\n",
       "   238         1          9.0      9.0      0.0          assert ant_tran.ndim == 2, \"ant: 2d tensor (n_antigens,n_features)\"\n",
       "   239                                           \n",
       "   240                                                   # make sure data and indices are in the same class\n",
       "   241         1         13.0     13.0      0.0          if isinstance(self.x_orig, torch.Tensor):\n",
       "   242         1        116.0    116.0      0.0              nbc_ind = torch.LongTensor(nbc_ind)\n",
       "   243                                           \n",
       "   244         1          2.0      2.0      0.0          pla_bcs = []\n",
       "   245         1          2.0      2.0      0.0          pla_labs = []\n",
       "   246         1          4.0      4.0      0.0          if self.keep_memory:\n",
       "   247                                                       mem_bcs = []\n",
       "   248                                                       mem_labs = []\n",
       "   249                                                   else:\n",
       "   250         1          2.0      2.0      0.0              mem_bcs = None\n",
       "   251         1          2.0      2.0      0.0              mem_labs = None\n",
       "   252         1         67.0     67.0      0.0          logger.info(\"Affinity maturation process starts with population of {}...\".format(self.n_population))\n",
       "   253         1          3.0      3.0      0.0          if self.return_log:\n",
       "   254                                                       ant_logs = []  # store the history dict in terms of metrics for antigens\n",
       "   255                                                   else:\n",
       "   256         1          2.0      2.0      0.0              ant_logs = None\n",
       "   257                                           \n",
       "   258      1001       2889.0      2.9      0.0          for n in range(ant.size(0)):\n",
       "   259      1000      10302.0     10.3      0.0              genop = GeneticOperator(self.mut_range[1], self.mut_prob[1], self.cliprg, type=self.genop_type)\n",
       "   260      1000   40376412.0  40376.4     17.0              curr_gen = torch.Tensor(self.x_orig[nbc_ind[n]]).to(self.device)  # naive b cells\n",
       "   261      1000     128613.0    128.6      0.1              labels = torch.LongTensor(self.y_orig[nbc_ind[n]]).to(self.device)\n",
       "   262      1000       2190.0      2.2      0.0              if self.requires_init:\n",
       "   263      1000       3186.0      3.2      0.0                  assert self.n_population % (self.n_class * self.n_neighbors) == 0, \\\n",
       "   264                                                               \"n_population should be divisible by the product of n_class and n_neighbors\"\n",
       "   265      1000     264576.0    264.6      0.1                  curr_gen = curr_gen.repeat_interleave(self.n_population // (self.n_class * self.n_neighbors), dim=0)\n",
       "   266      1000     185875.0    185.9      0.1                  curr_gen = genop.mutate(curr_gen, self.cliprg)  # initialize *NOTE: torch.Tensor.repeat <> numpy.repeat\n",
       "   267      1000     960273.0    960.3      0.4                  labels = labels.repeat_interleave(self.n_population // (self.n_class * self.n_neighbors))\n",
       "   268      1000       3060.0      3.1      0.0              head_shape = (self.n_class, self.n_population // self.n_class)\n",
       "   269      1000    1077954.0   1078.0      0.5              curr_repr = self._hidden_repr_mapping(curr_gen).reshape(head_shape+(-1,))\n",
       "   270      1000     277652.0    277.7      0.1              fitness_score = self.fitness_func(ant_tran[n].to(self.device), curr_repr.to(self.device))\n",
       "   271                                           \n",
       "   272      1000       5092.0      5.1      0.0              best_pop_fitness = float('-inf')\n",
       "   273      1000       1723.0      1.7      0.0              decay_coef = (1., 1.)\n",
       "   274      1000       1476.0      1.5      0.0              num_plateau = 0\n",
       "   275      1000       2830.0      2.8      0.0              ant_log = dict()  # history log for each antigen\n",
       "   276                                                       # zeroth generation logging\n",
       "   277      1000       1801.0      1.8      0.0              if self.return_log:\n",
       "   278                                                           fitness_pop_hist = []\n",
       "   279                                                           pop_fitness = fitness_score.sum().item()\n",
       "   280                                                           fitness_pop_hist.append(pop_fitness)\n",
       "   281                                                           if y_ant is not None:\n",
       "   282                                                               fitness_true_class_hist = []\n",
       "   283                                                               true_class_fitness = fitness_score[y_ant[n]].sum().item()\n",
       "   284                                                               fitness_true_class_hist.append(true_class_fitness)\n",
       "   285                                           \n",
       "   286                                                       # static index\n",
       "   287      1000   26305633.0  26305.6     11.1              static_index = torch.arange(self.n_population).reshape(head_shape).to(self.device)\n",
       "   288                                           \n",
       "   289     11000      23722.0      2.2      0.0              for i in range(self.max_generation):\n",
       "   290     10000     750493.0     75.0      0.3                  survival_prob = F.softmax(fitness_score / self.sampl_temp, dim=-1)\n",
       "   291     10000      27860.0      2.8      0.0                  if self.genop_type == \"crossover\":\n",
       "   292     10000    4041037.0    404.1      1.7                      parent_inds = Categorical(probs=survival_prob).sample((head_shape[1], 2))\n",
       "   293     10000     315016.0     31.5      0.1                      parent_inds1, parent_inds2 = parent_inds[:, 0, :].t(), parent_inds[:, 1, :].t()\n",
       "   294     20000     456862.0     22.8      0.2                      parent_inds1_flat, parent_inds2_flat = static_index.gather(-1, parent_inds1).flatten(),\\\n",
       "   295     10000     182414.0     18.2      0.1                                                             static_index.gather(-1, parent_inds2).flatten()\n",
       "   296     10000     526345.0     52.6      0.2                      parent_pairs = [curr_gen[parent_inds1_flat], curr_gen[parent_inds2_flat]]\n",
       "   297                                                               # crossover between two parents\n",
       "   298     10000      70021.0      7.0      0.0                      fitness_score_flat = fitness_score.flatten()\n",
       "   299     20000     336457.0     16.8      0.1                      select_prob = fitness_score_flat[parent_inds1_flat] /\\\n",
       "   300     10000     448009.0     44.8      0.2                                    (fitness_score_flat[parent_inds1_flat] + fitness_score_flat[parent_inds2_flat])\n",
       "   301     10000    2554687.0    255.5      1.1                      curr_gen = genop(parent_pairs, select_prob)\n",
       "   302                                                           else:\n",
       "   303                                                               parent_inds1 = Categorical(probs=survival_prob).sample((head_shape[1], 1))\n",
       "   304                                                               parent_inds1 = parent_inds1[:, 0, :].t()\n",
       "   305                                                               parent_inds_flat = static_index.gather(-1, parent_inds1).flatten()\n",
       "   306                                                               curr_gen = genop(curr_gen[parent_inds_flat])\n",
       "   307                                           \n",
       "   308     10000   10537746.0   1053.8      4.4                  curr_repr = self._hidden_repr_mapping(curr_gen).reshape(head_shape + (-1,))\n",
       "   309                                           \n",
       "   310     10000    1379040.0    137.9      0.6                  fitness_score = self.fitness_func(ant_tran[n].to(self.device), curr_repr.to(self.device))\n",
       "   311     10000  106883415.0  10688.3     45.0                  pop_fitness = fitness_score.sum().item()\n",
       "   312                                           \n",
       "   313     10000      41079.0      4.1      0.0                  if self.return_log:\n",
       "   314                                                               # logging\n",
       "   315                                                               fitness_pop_hist.append(pop_fitness)\n",
       "   316                                                               if y_ant is not None:\n",
       "   317                                                                   true_class_fitness = fitness_score[y_ant[n]].sum().item()\n",
       "   318                                                                   fitness_true_class_hist.append(true_class_fitness)\n",
       "   319                                           \n",
       "   320                                                           # adaptive shrinkage of certain hyper-parameters\n",
       "   321     10000      20145.0      2.0      0.0                  if self.decay:\n",
       "   322     10000     191671.0     19.2      0.1                      assert len(self.decay) == 2\n",
       "   323     10000      19722.0      2.0      0.0                      if pop_fitness < best_pop_fitness:\n",
       "   324      2320      14167.0      6.1      0.0                          if num_plateau >= max(math.log(self.mut_range[0] / self.mut_range[1], self.decay[0]),\n",
       "   325      1160       2900.0      2.5      0.0                                                math.log(self.mut_prob[0] / self.mut_prob[1], self.decay[1])):\n",
       "   326                                                                       # early stop\n",
       "   327                                                                       break\n",
       "   328      1160      13715.0     11.8      0.0                          decay_coef = tuple(decay_coef[i] * self.decay[i] for i in range(2))\n",
       "   329      1160       2178.0      1.9      0.0                          num_plateau += 1\n",
       "   330      2320      10070.0      4.3      0.0                          genop = GeneticOperator(\n",
       "   331      1160       2609.0      2.2      0.0                              max(self.mut_range[0], self.mut_range[1] * decay_coef[0]),\n",
       "   332      1160       2209.0      1.9      0.0                              max(self.mut_prob[0], self.mut_prob[1] * decay_coef[1]),\n",
       "   333      1160       1933.0      1.7      0.0                              self.cliprg,\n",
       "   334      1160       2793.0      2.4      0.0                              type=self.genop_type\n",
       "   335                                                                   )\n",
       "   336                                                               else:\n",
       "   337      8840      20351.0      2.3      0.0                          best_pop_fitness = pop_fitness\n",
       "   338                                           \n",
       "   339      1000     187089.0    187.1      0.1              _, fitness_rank = torch.sort(fitness_score.flatten().cpu())\n",
       "   340      1000       2109.0      2.1      0.0              if self.return_log:\n",
       "   341                                                           ant_log[\"fitness_pop\"] = fitness_pop_hist\n",
       "   342                                                           if y_ant is not None:\n",
       "   343                                                               ant_log[\"fitness_true_class\"] = fitness_true_class_hist\n",
       "   344      1000     716647.0    716.6      0.3              pla_bcs.append(curr_gen[fitness_rank[-self.n_plasma:]].detach().cpu())\n",
       "   345      1000     145792.0    145.8      0.1              pla_labs.append(labels[fitness_rank[-self.n_plasma:]].cpu().numpy())\n",
       "   346      1000       2405.0      2.4      0.0              if self.keep_memory:\n",
       "   347                                                           mem_bcs.append(curr_gen[fitness_rank[-(self.n_memory + self.n_plasma):-self.n_plasma]].detach().cpu())\n",
       "   348                                                           mem_labs.append(labels[fitness_rank[-(self.n_memory + self.n_plasma):-self.n_plasma]].cpu().numpy())\n",
       "   349      1000       6622.0      6.6      0.0              if self.return_log:\n",
       "   350                                                           ant_logs.append(ant_log)\n",
       "   351                                           \n",
       "   352         1   37783005.0 37783005.0     15.9          pla_bcs = torch.stack(pla_bcs).view((-1, self.n_plasma) + self.input_shape).numpy()\n",
       "   353         1      14247.0  14247.0      0.0          pla_labs = np.stack(pla_labs).astype(np.int)\n",
       "   354         1          4.0      4.0      0.0          if self.keep_memory:\n",
       "   355                                                       mem_bcs = torch.stack(mem_bcs).view((-1, self.n_mem) + self.input_shape).numpy()\n",
       "   356                                                       mem_labs = np.stack(mem_labs).astype(np.int)\n",
       "   357                                           \n",
       "   358         1          2.0      2.0      0.0          return mem_bcs, mem_labs, pla_bcs, pla_labs, ant_logs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "profile memory b-cell generation\n",
    "\"\"\"\n",
    "ant = x_start\n",
    "ant_tran = aise._hidden_repr_mapping(ant.detach())\n",
    "nbc_ind = aise._query_nns_ind(ant_tran.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "%lprun -f aise.generate_b_cells aise.generate_b_cells(ant.flatten(start_dim=1), ant_tran, nbc_ind, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
